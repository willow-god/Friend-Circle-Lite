# å¼•å…¥ check_feed å’Œ parse_feed å‡½æ•°
from friend_circle_lite.get_info import fetch_and_process_data, sort_articles_by_time, marge_data_from_json_url, marge_errors_from_json_url, deal_with_large_data
from friend_circle_lite.get_conf import load_config
from rss_subscribe.push_article_update import get_latest_articles_from_link, extract_emails_from_issues
from push_rss_update.send_email import send_emails

import logging
import json
import sys
import os

# æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO, format='ğŸ˜‹ %(levelname)s: %(message)s')


# çˆ¬è™«éƒ¨åˆ†å†…å®¹
config = load_config("./conf.yaml")
if config["spider_settings"]["enable"]:
    logging.info("çˆ¬è™«å·²å¯ç”¨")
    json_url = config['spider_settings']['json_url']
    article_count = config['spider_settings']['article_count']
    specific_RSS = config['specific_RSS']
    logging.info("æ­£åœ¨ä» {json_url} ä¸­è·å–ï¼Œæ¯ä¸ªåšå®¢è·å– {article_count} ç¯‡æ–‡ç« ".format(json_url=json_url, article_count=article_count))
    result, lost_friends = fetch_and_process_data(json_url=json_url, specific_RSS=specific_RSS, count=article_count)
    if config["spider_settings"]["merge_result"]["enable"]:
        marge_json_url = config['spider_settings']["merge_result"]['merge_json_url']
        logging.info("åˆå¹¶æ•°æ®åŠŸèƒ½å¼€å¯ï¼Œä» {marge_json_url} ä¸­è·å–å¢ƒå¤–æ•°æ®å¹¶åˆå¹¶".format(marge_json_url=marge_json_url + "/all.json"))
        result = marge_data_from_json_url(result, marge_json_url + "/all.json")
        lost_friends = marge_errors_from_json_url(lost_friends, marge_json_url + "/errors.json")
    logging.info("æ•°æ®è·å–å®Œæ¯•ï¼Œç›®å‰å…±æœ‰ {count} ä½å¥½å‹çš„åŠ¨æ€ï¼Œæ­£åœ¨å¤„ç†æ•°æ®".format(count=len(result.get("article_data", []))))
    result = deal_with_large_data(result)

    with open("all.json", "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    with open("errors.json", "w", encoding="utf-8") as f:
        json.dump(lost_friends, f, ensure_ascii=False, indent=2)

if config["email_push"]["enable"] or config["rss_subscribe"]["enable"]:
    logging.info("æ¨é€åŠŸèƒ½å·²å¯ç”¨ï¼Œæ­£åœ¨å‡†å¤‡æ¨é€ï¼Œè·å–é…ç½®ä¿¡æ¯")
    email_settings = config["smtp"]
    email = email_settings["email"]
    server = email_settings["server"]
    port = email_settings["port"]
    use_tls = email_settings["use_tls"]
    password = os.getenv("SMTP_PWD")
    logging.info("SMTP æœåŠ¡å™¨ä¿¡æ¯ï¼š{server}:{port}".format(server=server, port=port))
    logging.info("å¯†ç ï¼š{pwd}************".format(pwd=password[:3]))

if config["email_push"]["enable"]:
    logging.info("é‚®ä»¶æ¨é€å·²å¯ç”¨")
    logging.info("æŠ±æ­‰ï¼Œç›®å‰æš‚æœªå®ç°åŠŸèƒ½")
    
if config["rss_subscribe"]["enable"]:
    logging.info("RSS è®¢é˜…æ¨é€å·²å¯ç”¨")
    # è·å–å¹¶å¼ºåˆ¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    # å°è¯•ä»ç¯å¢ƒå˜é‡è·å– FCL_REPO
    fcl_repo = os.getenv('FCL_REPO')

    # æå– github_username å’Œ github_repo
    if fcl_repo:
        github_username, github_repo = fcl_repo.split('/')
    else:
        github_username = str(config["rss_subscribe"]["github_username"]).strip()
        github_repo = str(config["rss_subscribe"]["github_repo"]).strip()
    
    # è¾“å‡º github_username å’Œ github_repo
    logging.info("github_username: {github_username}".format(github_username=github_username))
    logging.info("github_repo: {github_repo}".format(github_repo=github_repo))
    
    your_blog_url = config["rss_subscribe"]["your_blog_url"]
    email_template = config["rss_subscribe"]["email_template"]
    # è·å–ç½‘ç«™ä¿¡æ¯
    website_title = config["rss_subscribe"]["website_info"]["title"]
    # è·å–æœ€è¿‘æ›´æ–°çš„æ–‡ç« 
    latest_articles = get_latest_articles_from_link(
        url=your_blog_url,
        count=5,
        last_articles_path="./rss_subscribe/last_articles.json"
        )
    logging.info("è·å–åˆ°çš„æœ€æ–°æ–‡ç« ä¸ºï¼š{latest_articles}".format(latest_articles=latest_articles))
    if latest_articles == None:
        logging.info("æ— æœªè¿›è¡Œæ¨é€çš„æ–°æ–‡ç« ")
    else:
        github_api_url = "https://api.github.com/repos/" + github_username + "/" + github_repo + "/issues" + "?state=closed&label=subscribed&per_page=200"
        logging.info("æ­£åœ¨ä» {github_api_url} ä¸­è·å–è®¢é˜…ä¿¡æ¯".format(github_api_url=github_api_url))
        email_list = extract_emails_from_issues(github_api_url)
        if email_list == None:
            logging.info("æ— é‚®ç®±åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥æ‚¨çš„è®¢é˜…åˆ—è¡¨æ˜¯å¦æœ‰è®¢é˜…è€…æˆ–è®¢é˜…æ ¼å¼æ˜¯å¦æ­£ç¡®")
            sys.exit(0)
        else:
            logging.info("è·å–åˆ°çš„é‚®ç®±åˆ—è¡¨ä¸ºï¼š{email_list}".format(email_list=email_list))
        # å¾ªç¯latest_articlesï¼Œå‘é€é‚®ä»¶
        for article in latest_articles:
            template_data = {
                "title": article["title"],
                "summary": article["summary"],
                "published": article["published"],
                "link": article["link"],
                "website_title": website_title,
                "github_issue_url": f"https://github.com/{github_username}/{github_repo}/issues?q=is%3Aissue+is%3Aclosed",
            }
            
            send_emails(
                emails=email_list["emails"],
                sender_email=email,
                smtp_server=server,
                port=port,
                password=password,
                subject= website_title + "ã®æœ€æ–°æ–‡ç« ï¼š" + article["title"],
                body="æ–‡ç« é“¾æ¥ï¼š" + article["link"] + "\n" + "æ–‡ç« å†…å®¹ï¼š" + article["summary"] + "\n" + "å‘å¸ƒæ—¶é—´ï¼š" + article["published"],
                template_path=email_template,
                template_data=template_data,
                use_tls=use_tls
            )
